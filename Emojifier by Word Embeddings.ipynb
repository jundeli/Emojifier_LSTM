{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural-language processing_2-layer LSTM classifier\n",
    "Project: Build A Emojifier for Sentiment Analysis                                           --By Junde Li on 27 Feb 2018\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using word vectors, even if training set explicitly relates only a few words to a particular emoji, the algorithm will be able to generalize and associate words in the test set to the same emoji even if those words don't even appear in the training set. This model will enable accurate classifier mapping from sentences to emojis with small data examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as panda\n",
    "import emoji\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation, Lambda\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1.1 Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset using csv, and split the dataset between training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in dataset by csv.\n",
    "phrase = []\n",
    "emoji = []\n",
    "with open ('data_emoji.csv') as csvfile:\n",
    "    items = csv.reader(csvfile)\n",
    "    \n",
    "    for i in items:\n",
    "        phrase.append(i[0])\n",
    "        emoji.append(i[1])\n",
    "        \n",
    "    X = np.asarray(phrase)\n",
    "    y = np.asarray(emoji, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Randomly split 20% of training set as test set.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 191\n",
      "Number of testing examples = 48\n",
      "Number of classes = 5\n",
      "Number of maximum lenth of sentences = 10\n"
     ]
    }
   ],
   "source": [
    "n_train = X_train.shape[0]\n",
    "n_test = X_test.shape[0]\n",
    "\n",
    "# Unique classes/labels there in the dataset.\n",
    "n_classes = len(np.unique(Y_train))\n",
    "\n",
    "maxLen = len(max(X_train, key=len).split())\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Number of classes =\", n_classes)\n",
    "print(\"Number of maximum lenth of sentences =\", maxLen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Data Visulization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to print 5 different labels from Y_train and corresponding sentences from X_train. Because of the font the iPython notebook uses, the heart emoji may be colored black rather than red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are you down for baseball this afternoon ‚öæ\n",
      "will you be my valentine\t ‚ù§Ô∏è\n",
      "cookies are good üç¥\n",
      "he got a raise üòÑ\n",
      "I am upset\t üòû\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "# Converts a label (int or string) into the corresponding emoji code (string)\n",
    "def label_to_emoji(label):\n",
    "    # Set up our own emoji dictionary for output (Here I just set up five emojis).\n",
    "    emoji_dictionary = {\"0\": \"\\u2764\\uFE0F\",\n",
    "                    \"1\": \":baseball:\",\n",
    "                    \"2\": \":smile:\",\n",
    "                    \"3\": \":disappointed:\",\n",
    "                    \"4\": \":fork_and_knife:\"}\n",
    "    return emoji.emojize(emoji_dictionary[str(label)], use_aliases=True)\n",
    "\n",
    "classes = []\n",
    "for i in range(len(X_train)):\n",
    "    index = np.random.randint(len(X_train))\n",
    "    if Y_train[index] not in classes:\n",
    "        print(X_train[index], label_to_emoji(Y_train[index]))\n",
    "        classes.append(Y_train[index])\n",
    "    if Y_train[index] in classes:\n",
    "        continue\n",
    "    # Break the for-loop if all classes show up.\n",
    "    if len(classes) == n_classes:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Design and test Emojifier: Using LSTMs in Keras: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below builds an LSTM model that takes as input word sequences. This model will be able to take word ordering into account. Emojifier will continue to use pre-trained word embeddings to represent words, but will feed them into an LSTM, whose job it is to predict the most appropriate emoji.\n",
    "\n",
    "Note: In order to train Keras using mini-batches, padding will be used to set all sentences to the same maximum lenth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 The Embedding Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the training set is quite small, we will not update the word embeddings but will instead leave their values fixed.\n",
    "\n",
    "The Embedding() layer takes an integer matrix of size (batch size, max input length) as input. This corresponds to sentences converted into lists of indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_glove_vecs(glove_file):\n",
    "    with open(glove_file, encoding='utf-8', mode = 'r') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "        \n",
    "        i = 1\n",
    "        words_to_index = {}\n",
    "        index_to_words = {}\n",
    "        for w in sorted(words):\n",
    "            words_to_index[w] = i\n",
    "            index_to_words[i] = w\n",
    "            i = i + 1\n",
    "    return words_to_index, index_to_words, word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    X_indices = np.zeros((m, max_len))\n",
    "    \n",
    "    for i in range(m):\n",
    "        \n",
    "        # Convert the ith training sentence in lower case and split is into words.\n",
    "        sentence_words = X[i].lower().split()\n",
    "        j = 0\n",
    "        \n",
    "        for w in sentence_words:\n",
    "            X_indices[i, j] = word_to_index[w]\n",
    "            j = j+1\n",
    "            \n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pretrained_embedding layer by importing the glove.6B.50d.txt (downloaded from https://www.kaggle.com/rohitanil/glove6b50dtxt).\n",
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    # Add 1 to fit Keras embedding (requirement).\n",
    "    vocab_len = len(word_to_index) + 1              \n",
    "    emb_dim = word_to_vec_map[\"good\"].shape[0]\n",
    "    \n",
    "    emb_matrix = np.zeros((vocab_len, emb_dim))\n",
    "    \n",
    "    # Set each row \"index\" of the embedding matrix to be the word vector representation.\n",
    "    for word, index in word_to_index.items():\n",
    "        emb_matrix[index, :] = word_to_vec_map[word]\n",
    "\n",
    "    embedding_layer = Embedding(vocab_len, emb_dim, input_length=None, trainable = False)\n",
    "    embedding_layer.build((None,))\n",
    "    \n",
    "    # Set the weights of the embedding layer to the embedding matrix.\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Build the Emojifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Emojify(input_shape, word_to_vec_map, word_to_index):\n",
    "    \n",
    "    # Define sentence_indices as the input of the graph.\n",
    "    sentence_indices = Input(shape = input_shape, dtype = 'int32')\n",
    "    \n",
    "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "    \n",
    "    # Propagate sentence_indices through embedding layer.\n",
    "    embeddings = embedding_layer(sentence_indices)\n",
    "    \n",
    "    # An LSTM layer with 128-dimensional hidden state (128 controls the memory lenth) with output of a batch of sequences.\n",
    "    X = LSTM(128, return_sequences=True)(embeddings)\n",
    "    X = Dropout(0.5)(X)\n",
    "    # X = LSTM(128, return_sequences=True)(X)   # 2-layer LSTM give good enough result.\n",
    "    # X = Dropout(0.5)(X)\n",
    "    X = LSTM(128)(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    # A Dense layer to get back a batch of 5-dimensional vectors.\n",
    "    X = Dense(5)(X)\n",
    "    # Add a softmax activation\n",
    "    X = Activation('softmax')(X)\n",
    "    \n",
    "    # Create Model instance which converts sentence_indices into X.\n",
    "    model = Model(inputs=sentence_indices, outputs=X)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 10, 50)            20000050  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 10, 128)           91648     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 20,223,927\n",
      "Trainable params: 223,877\n",
      "Non-trainable params: 20,000,050\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Emojify((maxLen,), word_to_vec_map, word_to_index)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2.3 Train and test Emojifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training the model, I convert the sentences and labels to indices and one-hot vectors separately for feeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
    "Y_train_oh = np.eye(5)[Y_train.reshape(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 1.5734 - acc: 0.2618\n",
      "Epoch 2/50\n",
      "191/191 [==============================] - 0s 871us/step - loss: 1.4809 - acc: 0.3194\n",
      "Epoch 3/50\n",
      "191/191 [==============================] - 0s 835us/step - loss: 1.4614 - acc: 0.3665\n",
      "Epoch 4/50\n",
      "191/191 [==============================] - 0s 871us/step - loss: 1.3427 - acc: 0.4555\n",
      "Epoch 5/50\n",
      "191/191 [==============================] - 0s 903us/step - loss: 1.2178 - acc: 0.5236\n",
      "Epoch 6/50\n",
      "191/191 [==============================] - 0s 772us/step - loss: 1.0684 - acc: 0.6126\n",
      "Epoch 7/50\n",
      "191/191 [==============================] - 0s 990us/step - loss: 0.8735 - acc: 0.6963\n",
      "Epoch 8/50\n",
      "191/191 [==============================] - 0s 934us/step - loss: 0.7929 - acc: 0.7539\n",
      "Epoch 9/50\n",
      "191/191 [==============================] - 0s 866us/step - loss: 0.5849 - acc: 0.8063\n",
      "Epoch 10/50\n",
      "191/191 [==============================] - 0s 856us/step - loss: 0.4843 - acc: 0.8482\n",
      "Epoch 11/50\n",
      "191/191 [==============================] - 0s 973us/step - loss: 0.4182 - acc: 0.8534\n",
      "Epoch 12/50\n",
      "191/191 [==============================] - 0s 916us/step - loss: 0.4007 - acc: 0.8743\n",
      "Epoch 13/50\n",
      "191/191 [==============================] - 0s 887us/step - loss: 0.2962 - acc: 0.9215\n",
      "Epoch 14/50\n",
      "191/191 [==============================] - 0s 950us/step - loss: 0.2729 - acc: 0.9215\n",
      "Epoch 15/50\n",
      "191/191 [==============================] - 0s 919us/step - loss: 0.2126 - acc: 0.9215\n",
      "Epoch 16/50\n",
      "191/191 [==============================] - 0s 845us/step - loss: 0.2704 - acc: 0.9058\n",
      "Epoch 17/50\n",
      "191/191 [==============================] - 0s 908us/step - loss: 0.2819 - acc: 0.9162\n",
      "Epoch 18/50\n",
      "191/191 [==============================] - 0s 903us/step - loss: 0.2531 - acc: 0.9110\n",
      "Epoch 19/50\n",
      "191/191 [==============================] - 0s 966us/step - loss: 0.2093 - acc: 0.9319\n",
      "Epoch 20/50\n",
      "191/191 [==============================] - 0s 903us/step - loss: 0.2204 - acc: 0.9581\n",
      "Epoch 21/50\n",
      "191/191 [==============================] - 0s 856us/step - loss: 0.1337 - acc: 0.9686\n",
      "Epoch 22/50\n",
      "191/191 [==============================] - 0s 971us/step - loss: 0.1339 - acc: 0.9634\n",
      "Epoch 23/50\n",
      "191/191 [==============================] - 0s 940us/step - loss: 0.1606 - acc: 0.9529\n",
      "Epoch 24/50\n",
      "191/191 [==============================] - 0s 929us/step - loss: 0.1211 - acc: 0.9686\n",
      "Epoch 25/50\n",
      "191/191 [==============================] - 0s 871us/step - loss: 0.1047 - acc: 0.9738\n",
      "Epoch 26/50\n",
      "191/191 [==============================] - 0s 892us/step - loss: 0.2620 - acc: 0.9215\n",
      "Epoch 27/50\n",
      "191/191 [==============================] - 0s 945us/step - loss: 0.2326 - acc: 0.9215\n",
      "Epoch 28/50\n",
      "191/191 [==============================] - 0s 850us/step - loss: 0.2806 - acc: 0.9005\n",
      "Epoch 29/50\n",
      "191/191 [==============================] - 0s 871us/step - loss: 0.1737 - acc: 0.9529\n",
      "Epoch 30/50\n",
      "191/191 [==============================] - 0s 927us/step - loss: 0.1386 - acc: 0.9529\n",
      "Epoch 31/50\n",
      "191/191 [==============================] - 0s 891us/step - loss: 0.1040 - acc: 0.9791\n",
      "Epoch 32/50\n",
      "191/191 [==============================] - 0s 887us/step - loss: 0.0758 - acc: 0.9791\n",
      "Epoch 33/50\n",
      "191/191 [==============================] - 0s 868us/step - loss: 0.0776 - acc: 0.9791\n",
      "Epoch 34/50\n",
      "191/191 [==============================] - 0s 892us/step - loss: 0.0547 - acc: 0.9843\n",
      "Epoch 35/50\n",
      "191/191 [==============================] - 0s 992us/step - loss: 0.0482 - acc: 0.9895\n",
      "Epoch 36/50\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0379 - acc: 0.9895\n",
      "Epoch 37/50\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.0300 - acc: 0.9895\n",
      "Epoch 38/50\n",
      "191/191 [==============================] - 0s 976us/step - loss: 0.0333 - acc: 0.9895\n",
      "Epoch 39/50\n",
      "191/191 [==============================] - 0s 908us/step - loss: 0.0416 - acc: 0.9843\n",
      "Epoch 40/50\n",
      "191/191 [==============================] - 0s 892us/step - loss: 0.0396 - acc: 0.9895\n",
      "Epoch 41/50\n",
      "191/191 [==============================] - 0s 882us/step - loss: 0.0561 - acc: 0.9791\n",
      "Epoch 42/50\n",
      "191/191 [==============================] - 0s 945us/step - loss: 0.0280 - acc: 0.9948\n",
      "Epoch 43/50\n",
      "191/191 [==============================] - 0s 835us/step - loss: 0.0459 - acc: 0.9791\n",
      "Epoch 44/50\n",
      "191/191 [==============================] - 0s 987us/step - loss: 0.0414 - acc: 0.9895\n",
      "Epoch 45/50\n",
      "191/191 [==============================] - 0s 955us/step - loss: 0.0349 - acc: 0.9948\n",
      "Epoch 46/50\n",
      "191/191 [==============================] - 0s 898us/step - loss: 0.0251 - acc: 0.9895\n",
      "Epoch 47/50\n",
      "191/191 [==============================] - 0s 824us/step - loss: 0.0293 - acc: 0.9843\n",
      "Epoch 48/50\n",
      "191/191 [==============================] - 0s 840us/step - loss: 0.0552 - acc: 0.9738\n",
      "Epoch 49/50\n",
      "191/191 [==============================] - 0s 814us/step - loss: 0.0852 - acc: 0.9634\n",
      "Epoch 50/50\n",
      "191/191 [==============================] - 0s 940us/step - loss: 0.0655 - acc: 0.9686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c18192bf98>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_indices, Y_train_oh, epochs = 50, batch_size = 32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 2ms/step\n",
      "\n",
      "Test accuracy =  0.833333333333\n",
      "The accuracy is achieved by only 191 training samples.\n"
     ]
    }
   ],
   "source": [
    "X_test_indices = sentences_to_indices(X_test, word_to_index, max_len = maxLen)\n",
    "Y_test_oh = np.eye(5)[Y_test.reshape(-1)]\n",
    "loss, acc = model.evaluate(X_test_indices, Y_test_oh)\n",
    "print()\n",
    "print(\"Test accuracy = \", acc)\n",
    "print(\"The accuracy is achieved by only 191 training samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected emoji:üòÑ prediction: What you did was awesome‚ù§Ô∏è\n",
      "Expected emoji:üòû prediction: you got a down grade‚ù§Ô∏è\n",
      "Expected emoji:üòû prediction: you sucküòÑ\n",
      "Expected emoji:üòÑ prediction: What you did was awesome\t‚ù§Ô∏è\n",
      "Expected emoji:‚öæ prediction: lets exerciseüòÑ\n",
      "Expected emoji:üòû prediction: This girl is messing with me‚ù§Ô∏è\n",
      "Expected emoji:üòû prediction: the party is cancelledüòÑ\n",
      "Expected emoji:üòû prediction: I am very disappointedüòÑ\n"
     ]
    }
   ],
   "source": [
    "# Below show mislabelled examples.\n",
    "C = 5\n",
    "y_test_oh = np.eye(C)[Y_test.reshape(-1)]\n",
    "X_test_indices = sentences_to_indices(X_test, word_to_index, maxLen)\n",
    "pred = model.predict(X_test_indices)\n",
    "for i in range(len(X_test)):\n",
    "    x = X_test_indices\n",
    "    num = np.argmax(pred[i])\n",
    "    if(num != Y_test[i]):\n",
    "        print('Expected emoji:'+ label_to_emoji(Y_test[i]) + ' prediction: '+ X_test[i] + label_to_emoji(num).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try our own examples. Please make sure all the words we write are in the Glove embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thanks for your reading üòÑ\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array(['Thanks for your reading'])\n",
    "X_test_indices = sentences_to_indices(x_test, word_to_index, maxLen)\n",
    "print(x_test[0] +' '+  label_to_emoji(np.argmax(model.predict(X_test_indices))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Acknowledgments\n",
    "\n",
    "Thanks to Dr. Andrew Ng and his team for providing the learning materials and insights for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
